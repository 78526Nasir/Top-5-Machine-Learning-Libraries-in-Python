{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 5 Machine Learning Libraries in Python\n",
    "In this article we are going to learn about __Sci-kit__ Learn.\n",
    "\n",
    "__Sci-kit__ learn is a library that provides a range of Supervised and Unsupervised Learning Algorithms. This library mainly focused on model building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An End to End Model using Sci-kitÂ Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly we need to import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Supervised Classification Learning Algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, auc, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   math  bangla  english  result\n",
      "0    70      80       90       1\n",
      "1    30      40       50       0\n",
      "2    50      20       35       0\n",
      "3    80      33       33       1\n",
      "4    33      35       36       1\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(r\"../dataset/student_result.csv\")\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(\"result\", axis=1)\n",
    "y = dataset[\"result\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr = LogisticRegression()\n",
    "pred_lr = clf_lr.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "clf_knn = KNeighborsClassifier()\n",
    "pred_knn = clf_knn.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "clf_rf = RandomForestClassifier(random_state=1)\n",
    "pred_rf = clf_rf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "pred_dt = clf_dt.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression: 0.8\n",
      "Accuracy of KNN: 0.6\n",
      "Accuracy of Random Forest: 0.8\n",
      "Accuracy of Decision Tree: 0.8\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Logistic Regression:\", accuracy_score(pred_lr, y_test))\n",
    "print(\"Accuracy of KNN:\", accuracy_score(pred_knn, y_test))\n",
    "print(\"Accuracy of Random Forest:\", accuracy_score(pred_rf, y_test))\n",
    "print(\"Accuracy of Decision Tree:\", accuracy_score(pred_dt, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      1.00      0.67         1\n",
      "          1       1.00      0.75      0.86         4\n",
      "\n",
      "avg / total       0.90      0.80      0.82         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_lr, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80         3\n",
      "          1       0.67      1.00      0.80         2\n",
      "\n",
      "avg / total       0.87      0.80      0.80         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_rf, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         0\n",
      "          1       1.00      0.60      0.75         5\n",
      "\n",
      "avg / total       1.00      0.60      0.75         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DIU\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_knn, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      1.00      0.67         1\n",
      "          1       1.00      0.75      0.86         4\n",
      "\n",
      "avg / total       0.90      0.80      0.82         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_dt, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(pred_lr, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1]\n",
      " [0 2]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(pred_rf, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(pred_dt, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [2 3]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(pred_knn, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
